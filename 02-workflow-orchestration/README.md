<div align="center">

# ğŸš€ Workflow Orchestration with Kestra

### Data Engineering Zoomcamp - Module 2

[![Kestra](https://img.shields.io/badge/Kestra-v1.1-blue?style=flat&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAACGSURBVHgBnZLBDYAwDAPjASwhI7ACbMAGbMAGsAEjsAEbsAGsQPpQqRT1AZbqSJaTOHEA/hcBqKqIyExE5lLKQUQmVZ0AjKp6EJEJwKCqHRFZAAwABgBDKWVQ1Y6IzAAGVe2IyAxgUNWOiMwABlXtiMgMYFDVjojMAAZV7YjIDGBQ1a6U8gKwA1kfXvHyXQAAAABJRU5ErkJggg==)](https://kestra.io)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?style=flat&logo=docker&logoColor=white)](https://www.docker.com/)
[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=flat&logo=python&logoColor=white)](https://www.python.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-18-316192?style=flat&logo=postgresql&logoColor=white)](https://www.postgresql.org/)
[![Google Cloud](https://img.shields.io/badge/Google_Cloud-BigQuery-4285F4?style=flat&logo=google-cloud&logoColor=white)](https://cloud.google.com/)

**Building production-ready data pipelines with modern orchestration tools**

[Overview](#-overview) â€¢
[Workflows](#-completed-workflows) â€¢
[Quick Start](#-quick-start) â€¢
[Tech Stack](#ï¸-tech-stack) â€¢
[Resources](#-resources)

</div>

---

## ğŸ“– Overview

This repository showcases my completion of **Module 2: Workflow Orchestration** from the [Data Engineering Zoomcamp](https://github.com/DataTalksClub/data-engineering-zoomcamp). 

The project demonstrates end-to-end data pipeline development using **Kestra**, exploring both **ETL** (Extract-Transform-Load) and **ELT** (Extract-Load-Transform) patterns with real-world NYC Taxi & Limousine Commission data.

### What I Built:
- ğŸ”„ **8 production-ready workflows** for data ingestion and transformation
- ğŸ˜ **Local Postgres pipelines** with scheduling and backfilling
- â˜ï¸ **Cloud-native GCP pipelines** using BigQuery and Cloud Storage
- ğŸ **Python integration** for custom data transformations
- â° **Automated scheduling** with cron-based triggers
- ğŸ¯ **AI-assisted development** using Kestra's Copilot

---

## ğŸ“š Table of Contents

- [Project Structure](#-project-structure)
- [Completed Workflows](#-completed-workflows)
- [Architecture](#-architecture)
- [Tech Stack](#ï¸-tech-stack)
- [Quick Start](#-quick-start)
- [Key Learnings](#-key-learnings)
- [Resources](#-resources)

---

## ğŸ“ Project Structure

```
02-workflow-orchestration/
â”œâ”€â”€ docker-compose.yaml        # Kestra + Postgres setup
â”œâ”€â”€ kestra-sandbox.json        # Kestra configuration
â”œâ”€â”€ flows/                     # All Kestra workflow YAML files
â”‚   â”œâ”€â”€ 02_python.yaml        # Python script orchestration
â”‚   â”œâ”€â”€ 03_getting_started_data_pipeline.yaml  # Basic ETL pipeline
â”‚   â”œâ”€â”€ 04_postgres_taxi.yaml     # Load taxi data to Postgres
â”‚   â”œâ”€â”€ 05_postgres_taxi_scheduled.yaml  # Scheduled Postgres pipeline
â”‚   â”œâ”€â”€ 06_gcp_kv.yaml           # GCP credentials setup
â”‚   â”œâ”€â”€ 07_gcp_setup.yaml        # GCP resource creation
â”‚   â”œâ”€â”€ 08_gcp_taxi.yaml         # Load taxi data to BigQuery
â”‚   â””â”€â”€ 9_gcp_taxi_schedule.yaml # Scheduled BigQuery pipeline
â””â”€â”€ README.md                   # This file
```

---

## ğŸ”„ Completed Workflows

<table>
<tr>
<td width="50%">

### ğŸ  Local Database Pipelines

| Workflow | Description |
|----------|-------------|
| **[02_python.yaml](flows/02_python.yaml)** | Python script orchestration with Docker Hub API |
| **[03_getting_started_data_pipeline.yaml](flows/03_getting_started_data_pipeline.yaml)** | Basic ETL with HTTP, Python & DuckDB |
| **[04_postgres_taxi.yaml](flows/04_postgres_taxi.yaml)** | NYC Taxi data â†’ Postgres with monthly partitioning |
| **[05_postgres_taxi_scheduled.yaml](flows/05_postgres_taxi_scheduled.yaml)** | Scheduled pipeline with backfilling (9 AM UTC) |

</td>
<td width="50%">

### â˜ï¸ Cloud Pipelines (GCP)

| Workflow | Description |
|----------|-------------|
| **[06_gcp_kv.yaml](flows/06_gcp_kv.yaml)** | GCP credentials configuration |
| **[07_gcp_setup.yaml](flows/07_gcp_setup.yaml)** | Automated GCS + BigQuery setup |
| **[08_gcp_taxi.yaml](flows/08_gcp_taxi.yaml)** | ELT: CSV â†’ GCS â†’ BigQuery |
| **[9_gcp_taxi_schedule.yaml](flows/9_gcp_taxi_schedule.yaml)** | Dual-schedule pipeline (Yellow & Green) |

</td>
</tr>
</table>

---

## ğŸ—ï¸ Architecture

### ETL Pipeline (Local - Postgres)
```mermaid
graph LR
    A[ğŸŒ Extract CSV from GitHub] --> B[ğŸ Transform with Python]
    B --> C[ğŸ˜ Load to PostgreSQL]
    C --> D[ğŸ“Š Query & Analyze]
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#e8f5e9
    style D fill:#f3e5f5
```

### ELT Pipeline (Cloud - BigQuery)
```mermaid
graph LR
    A[ğŸŒ Extract CSV] --> B[â˜ï¸ Load to GCS]
    B --> C[ğŸ“Š External Table in BigQuery]
    C --> D[ğŸ”„ Transform in BigQuery]
    D --> E[âœ… Production Table]
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#e8f5e9
    style D fill:#fff59d
    style E fill:#c8e6c9
```

---

## ğŸ› ï¸ Tech Stack

<div align="center">

| Category | Technologies |
|----------|-------------|
| **Orchestration** | Kestra (v1.1) |
| **Containerization** | Docker, Docker Compose |
| **Databases** | PostgreSQL 18, DuckDB |
| **Cloud** | Google Cloud Platform (GCS, BigQuery) |
| **Languages** | Python 3.11+, SQL, YAML |
| **Data Source** | NYC TLC Trip Record Data |

</div>

---

## ğŸš€ Quick Start

### Prerequisites

Before you begin, ensure you have:

- âœ… Docker & Docker Compose installed ([Download here](https://www.docker.com/get-started))
- âœ… GCP account with service account (for cloud pipelines - [Setup guide](https://cloud.google.com/iam/docs/service-accounts))
- âœ… 8GB RAM minimum for smooth Docker operations

### Installation

1ï¸âƒ£ **Clone the repository**
```bash
git clone <your-repo-url>
cd 02-workflow-orchestration
```

2ï¸âƒ£ **Start Kestra services**
```bash
docker compose up -d
```

3ï¸âƒ£ **Access Kestra UI**

Open your browser and navigate to: **http://localhost:8080**

4ï¸âƒ£ **Run your first workflow**
- Navigate to **Flows** in the Kestra UI
- Select any workflow (try `03_getting_started_data_pipeline.yaml` first)
- Click **Execute** button
- Monitor execution in real-time

### Stopping Services

```bash
docker compose down
```

To remove all data and start fresh:
```bash
docker compose down -v
```

---

## ğŸ’¡ Key Learnings

<details>
<summary><b>ğŸ¯ Workflow Orchestration Fundamentals</b></summary>

- Understanding the role of orchestrators in data engineering
- Comparing orchestration tools (Kestra, Airflow, Prefect)
- Building declarative workflows with YAML
- Event-driven vs scheduled workflows
</details>

<details>
<summary><b>ğŸ”„ ETL vs ELT Patterns</b></summary>

- **ETL**: Transform data locally before loading (good for small datasets)
- **ELT**: Load first, transform in the warehouse (scalable for large datasets)
- When to use each pattern based on data volume and complexity
</details>

<details>
<summary><b>â° Scheduling & Backfilling</b></summary>

- Cron-based scheduling for automated pipeline execution
- Backfilling historical data without duplicates
- Handling incremental data loads with partitioning
</details>

<details>
<summary><b>â˜ï¸ Cloud-Native Data Engineering</b></summary>

- Migrating from local Postgres to cloud-based BigQuery
- Using GCS as a data lake for staging raw data
- Leveraging BigQuery's compute for transformations
- Managing cloud credentials securely
</details>

<details>
<summary><b>ğŸ¤– AI-Assisted Development</b></summary>

- Using Kestra's AI Copilot to generate workflows
- Understanding context engineering for better AI outputs
- RAG (Retrieval Augmented Generation) in data pipelines
</details>

---

## ğŸ“Š Project Highlights

| Metric | Achievement |
|--------|-------------|
| **Workflows Built** | 8 production-ready pipelines |
| **Data Processed** | NYC Taxi data (Yellow & Green taxis) |
| **Pipeline Types** | ETL (Postgres) + ELT (BigQuery) |
| **Automation** | Scheduled daily execution with backfilling |
| **Cloud Integration** | GCS + BigQuery + Docker |
| **Languages Used** | Python, SQL, YAML |

---

## ğŸ“š Resources & Documentation

### Official Course Materials
- ğŸ“º [Module 2 Video Playlist](https://www.youtube.com/playlist?list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb)
- ğŸ“– [Course Repository](https://github.com/DataTalksClub/data-engineering-zoomcamp)
- ğŸ’¬ [Community Slack](https://datatalks.club/slack.html)

### Kestra Resources
- ğŸ“˜ [Kestra Documentation](https://kestra.io/docs)
- ğŸ¯ [Kestra Blueprints](https://kestra.io/blueprints)
- ğŸ”Œ [Plugin Library (600+)](https://kestra.io/plugins)
- â­ [GitHub Repository](https://github.com/kestra-io/kestra)

### NYC Taxi Dataset
- ğŸ“Š [TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)

---

## ğŸ“ About This Course

<div align="center">

**Data Engineering Zoomcamp**  
*A free online bootcamp by [DataTalksClub](https://datatalks.club/)*

**Module 2: Workflow Orchestration**  
**Completion Date:** February 2026  
**Cohort:** 2026

</div>

---

## ğŸ¤ Contributing

Found an issue or have suggestions? Feel free to:
- Open an issue
- Submit a pull request
- Share your feedback

---

## ğŸ“ License

This project is part of the Data Engineering Zoomcamp course materials. Please refer to the [original course repository](https://github.com/DataTalksClub/data-engineering-zoomcamp) for license information.

---

## ğŸŒŸ Acknowledgments

- **[DataTalksClub](https://datatalks.club/)** for the excellent free course
- **[Kestra Team](https://kestra.io/)** for their amazing orchestration platform
- **NYC TLC** for providing the open dataset

---

<div align="center">

### ğŸš€ If you found this helpful, please â­ star this repository!

**[Back to Top](#-workflow-orchestration-with-kestra)**

---

Made with â¤ï¸ as part of Data Engineering Zoomcamp 2026

</div>
